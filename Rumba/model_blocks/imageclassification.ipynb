{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03b9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df6f5942",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = datasets.MNIST(root ='./data',train = True,download= True,transform = transform)\n",
    "test_dataset = datasets.MNIST(root ='./data',train = False,download= True,transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8241751",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset,batch_size = batch_size,shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size = batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b75df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n",
      "Batch size: 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4c30e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image tensor shape: torch.Size([64, 1, 28, 28])\n",
      "Label tensor shape: torch.Size([64])\n",
      "\n",
      "Labels in this batch: [9, 1, 4, 4, 5, 4, 0, 9, 2, 7]...\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_dataloader))\n",
    "print(\"Image tensor shape:\", X.shape)\n",
    "print(\"Label tensor shape:\", y.shape)\n",
    "print(f\"\\nLabels in this batch: {y[:10].tolist()}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79be1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP,self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(784, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(128,64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(64,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "model = SimpleMLP()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6693081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr =0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "421fee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/5, Batch 100/938, Loss: 1.0121\n",
      "Epoch 1/5, Batch 200/938, Loss: 0.7086\n",
      "Epoch 1/5, Batch 300/938, Loss: 0.5796\n",
      "Epoch 1/5, Batch 400/938, Loss: 0.5098\n",
      "Epoch 1/5, Batch 500/938, Loss: 0.4613\n",
      "Epoch 1/5, Batch 600/938, Loss: 0.4278\n",
      "Epoch 1/5, Batch 700/938, Loss: 0.4000\n",
      "Epoch 1/5, Batch 800/938, Loss: 0.3774\n",
      "Epoch 1/5, Batch 900/938, Loss: 0.3571\n",
      "Epoch 2/5, Batch 100/938, Loss: 0.1791\n",
      "Epoch 2/5, Batch 200/938, Loss: 0.1662\n",
      "Epoch 2/5, Batch 300/938, Loss: 0.1639\n",
      "Epoch 2/5, Batch 400/938, Loss: 0.1612\n",
      "Epoch 2/5, Batch 500/938, Loss: 0.1594\n",
      "Epoch 2/5, Batch 600/938, Loss: 0.1551\n",
      "Epoch 2/5, Batch 700/938, Loss: 0.1507\n",
      "Epoch 2/5, Batch 800/938, Loss: 0.1475\n",
      "Epoch 2/5, Batch 900/938, Loss: 0.1447\n",
      "Epoch 3/5, Batch 100/938, Loss: 0.1082\n",
      "Epoch 3/5, Batch 200/938, Loss: 0.1016\n",
      "Epoch 3/5, Batch 300/938, Loss: 0.1010\n",
      "Epoch 3/5, Batch 400/938, Loss: 0.0995\n",
      "Epoch 3/5, Batch 500/938, Loss: 0.0990\n",
      "Epoch 3/5, Batch 600/938, Loss: 0.0976\n",
      "Epoch 3/5, Batch 700/938, Loss: 0.0970\n",
      "Epoch 3/5, Batch 800/938, Loss: 0.0991\n",
      "Epoch 3/5, Batch 900/938, Loss: 0.0981\n",
      "Epoch 4/5, Batch 100/938, Loss: 0.0713\n",
      "Epoch 4/5, Batch 200/938, Loss: 0.0684\n",
      "Epoch 4/5, Batch 300/938, Loss: 0.0705\n",
      "Epoch 4/5, Batch 400/938, Loss: 0.0700\n",
      "Epoch 4/5, Batch 500/938, Loss: 0.0722\n",
      "Epoch 4/5, Batch 600/938, Loss: 0.0727\n",
      "Epoch 4/5, Batch 700/938, Loss: 0.0736\n",
      "Epoch 4/5, Batch 800/938, Loss: 0.0737\n",
      "Epoch 4/5, Batch 900/938, Loss: 0.0730\n",
      "Epoch 5/5, Batch 100/938, Loss: 0.0492\n",
      "Epoch 5/5, Batch 200/938, Loss: 0.0548\n",
      "Epoch 5/5, Batch 300/938, Loss: 0.0565\n",
      "Epoch 5/5, Batch 400/938, Loss: 0.0565\n",
      "Epoch 5/5, Batch 500/938, Loss: 0.0561\n",
      "Epoch 5/5, Batch 600/938, Loss: 0.0545\n",
      "Epoch 5/5, Batch 700/938, Loss: 0.0554\n",
      "Epoch 5/5, Batch 800/938, Loss: 0.0552\n",
      "Epoch 5/5, Batch 900/938, Loss: 0.0555\n",
      "Epoch 5/5 completed. Average Loss: 0.0562\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model,loss_fn, optimizer,epochs = 5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss= 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for batch_idx,(X,y) in enumerate(dataloader):\n",
    "            pred = model(X)\n",
    "\n",
    "            loss = loss_fn(pred,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "            num_batches+=1\n",
    "\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                avg_loss = total_loss/num_batches\n",
    "                print(f'Epoch {epoch + 1}/{epochs}, Batch {batch_idx + 1}/{len(dataloader)}, Loss: {avg_loss:.4f}')\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f'Epoch {epoch + 1}/{epochs} completed. Average Loss: {avg_loss:.4f}\\n')\n",
    "# Train the model\n",
    "print(\"Starting training...\\n\")\n",
    "train(train_dataloader, model, loss_fn, optimizer, epochs=5)\n",
    "print(\"Training completed!\")           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
